# Interactive recommender systems: A survey of the state of the art and future research challenges and opportunities
Autores: C. He, D. Parra, K. Verbert

## Breve Resumen
<p align="justify">
  Muchas veces, los sistemas recomendadores se ven como cajas negras, lo que impide a los usuarios saber por qué recibieron una recomendación dada. Sin embargo, en los últimos años, los investigadores se han dado cuenta de que la efectividad de los sistemas recomendadores va más allá de la precisión. Entonces, han investigado técnicas que entreguen mayor transparencia y control sobre el proceso de recomendación a los usuarios como, por ejemplo, técnicas de visualización interactiva. En este contexto, los autores buscan peresentar un framework de visualización interactiva para sistemas recomendadores. Para ello, primero se describen distintos tipos de algoritmos existentes (collaborative filtering, content-based, context-aware). Segundo, se describen algunos puntos relevantes sobre las técnicas de visualización existentes, tales como la separación de su estudio entre visualización de información y visualización científica. Tercero, se describe el framework propuesto así como los objetivos que se busca lograr (transparencia, justificación, control, diversidad, mitigar el cold start y adquirir información contextual). Cuarto, se describen algunas de las aproximaciones de recomendación interactiva clasificadas según los objetivos ya descritos. Los autores finalizan el paper con un análisis de los resultados obtenidos de la clasificación por objetivo, así como con una sección describiendo futuros desafíos a nivel de sistemas recomendadores, ético (problema de la privacidad) y de técnicas de visualización.
</p>

## Crítica personal

<p align="justify">
  Se indica que la visualización de información utiliza los principios de la Teoría de la Gestalt como la proximidad, similaridad, continuidad, simetría, cierre y tamaño relativo. Además de esto, sería interesante considerar el principio de esta teoría, pero en el área de la psicología, que indica que "el todo es más que la suma de las partes". Más aún, podría decirse que la idea de incluir el contexto en los sistemas recomendadores, así como la idea de incluir técnicas de visualización que permitan incorporar más fuertemente al usuario, irían en la dirección de considerar el todo al momento de recomendar más que recomendar solo por un subconjunto dado de aspectos.
</p>

<p align="justify">
  Se hace un punto interesanta al mencionar que la justificación puede ser preferida ante la transparencia. Cuando se habla de deep learning, uno de los primeros problemas que se menciona es que muchas veces no se logra entender al 100% por qué los modelos arrojan ciertos resultados, incluso para quienes trabajan en el área del deep learning. Entonces, si el deep learning parece ser una de las grandes mejoras en el dominio de los sistemas recomendadores, ¿cómo podría explicarse a un usuario promedio cómo se llegó a la recomendación si ni siquiera los desarrolladores del sistema logran entenderlo con exactitud? De hecho, en esta misma línea, la Figura 24 de la parte de análisis muestra que ninguno de los sistemas recomendadores analizados que aplican técnicas para mejorar la transparencia utilizan el contexto. No obstante, es interesante también que se mencione que 11 sistemas del sondeo realizado dan soporte a la transparencia, mientras que solo 7 lo hagan con la justificación. Quizá esto sea una especie de indicio de un intento de incorporar al usuario en el mundo de los sistemas recomendadores, de suavizar esa idea de que son áreas "demasiado complejas" o de democratizar el conocimiento al respecto.
</p>

<p align="justify">
  Como punto de curiosidad y fuera del contexto del contenido principal del paper, es interesante que se utilice el pronombre "she" al referirse a un usuario. No estoy seguro de que haya sido algo que ocurrió en la totalidad del documento, pero sí vi su uso en más de una sección.
</p>


<p align="justify">
  Es destacable el tema de la privacidad igualmente. Por ejemplo, a nivel de control se menciona que el sistema PARIS utiliza información proveniente de Facebook para inferir y representar características de personalidad del usuario. Esto tiene varias implicancias: en primer lugar, el usuario debe dar consentimiento explícito (o debería) para que utilicen la información de su perfil en Facebook. Esto muy probablemente llevaría al usuario a cuestionarse qué tipo de información va a ser accedida y a cómo va a ser utilizada y, eventualmente, guardada por el sistema recomendador. Asimismo, esto lleva a la necesidad por parte del proveedor del sistema recomendador de desarrollar alguna especia de contrato de "términos y condiciones" que sea claro para el usuario. Finalmente, se tiene que debe llegar a existir una confianza entre el usuario y el sistema recomendador para que entregue este tipo de información. Particularmente, en el caso de PARIS se observa que da soporte tanto a la transparencia como al control, lo que podría ser un indicio de intento de generar confianza en el usuario (transparencia) para poder acceder a sus datos (control) y ofrecer mejores recomendaciones.
</p>
